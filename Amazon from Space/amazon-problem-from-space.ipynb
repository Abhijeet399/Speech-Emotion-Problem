{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d4799295-64c0-3538-c3c3-cd5b3f52bf13",
    "_uuid": "b9244f1d8b07ffe9148d545b58f2426593df9748"
   },
   "source": [
    "# Planet: Understanding the Amazon deforestation from Space challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from subprocess import check_output\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import bernoulli\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from glob import glob # handles pathnames \n",
    "%matplotlib inline\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "from skimage import io\n",
    "import tifffile\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import keras as k\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print filenames of input datasets\n",
    "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv('../input/train_v2.csv')\n",
    "labels_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all unique classes\n",
    "from itertools import chain\n",
    "labels_list = list(chain.from_iterable([tags.split(\" \") for tags in labels_df['tags'].values]))\n",
    "num_labels = len(labels_list)\n",
    "uniq_labels = set(labels_list) \n",
    "num_uniq_labels = len(uniq_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_s = pd.Series(labels_list).value_counts() # To sort them by count\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "sns.barplot(x=labels_s, y=labels_s.index, orient='h')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess labels\n",
    "x_train = []\n",
    "x_test = []\n",
    "y_train = []\n",
    "\n",
    "df_train = pd.read_csv('../input/train_v2.csv')\n",
    "\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "labels = list(set(flatten([l.split(' ') for l in df_train['tags'].values])))\n",
    "\n",
    "label_map = {l: i for i, l in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df_train['tags'].apply(lambda x: x.split(' '))\n",
    "from collections import Counter, defaultdict\n",
    "counts = defaultdict(int)\n",
    "for l in labels:\n",
    "    for l2 in l:\n",
    "        counts[l2] += 1\n",
    "\n",
    "data=[go.Bar(x=list(counts.keys()), y=list(counts.values()))]\n",
    "layout=dict(height=800, width=800, title='Distribution of training labels')\n",
    "fig=dict(data=data, layout=layout)\n",
    "py.iplot(data, filename='train-label-dist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(3, 3, sharex='col', sharey='row', figsize=(20, 20))\n",
    "i = 0\n",
    "for f, l in df_train[:9].values:\n",
    "    img = cv2.imread('../input/train-jpg/{}.jpg'.format(f))\n",
    "    ax[i // 3, i % 3].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    ax[i // 3, i % 3].set_title('{} - {}'.format(f, l))\n",
    "    #ax[i // 4, i % 4].show()\n",
    "    i += 1\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f, tags in tqdm(df_train.values, miniters=1000):\n",
    "    img = cv2.imread('../input/train-jpg/{}.jpg'.format(f))\n",
    "    targets = np.zeros(17)\n",
    "    for t in tags.split(' '):\n",
    "        targets[label_map[t]] = 1 \n",
    "    x_train.append(cv2.resize(img, (32, 32)))\n",
    "    y_train.append(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value = np.amax(x_train)\n",
    "min_value = np.amin(x_train)\n",
    "\n",
    "print('Min value in the training images array: ', min_value)\n",
    "print('Max value in the training images array: ', max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "x_train = np.array(x_train) / 255.\n",
    "print(\"Shape of the training images array is: \")\n",
    "print(x_train.shape)\n",
    "print(\"Shape of the training labels array is: \")\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " y_train = np.array(y_train, np.uint8)\n",
    " x_train = np.array(x_train, np.float16) / 255.\n",
    " print(\"Shape of the training images array is: \")\n",
    " print(x_train.shape)\n",
    " print(\"Shape of the training labels array is: \")\n",
    " print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approx. 86% for training and 14% for validation\n",
    "x_train, x_valid, y_train, y_valid = (x_train[:35000], x_train[35000:], y_train[:35000], y_train[35000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create structure of Convolutional Neural Network\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(5, 5),\n",
    "                 activation='relu',\n",
    "                 input_shape=(32, 32, 3)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(17, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              # We NEED binary here, since categorical_crossentropy \n",
    "              # l1 norms the output before calculating loss.\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=12,\n",
    "          verbose=1,\n",
    "          validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot model accuracy and loss\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 3), sharey=False)\n",
    "plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=0.5, wspace=0.4)\n",
    "\n",
    "#axs[0].plot(history.history['acc'])\n",
    "#axs[0].plot(history.history['val_acc'])\n",
    "axs[0].set_title('model accuracy')\n",
    "axs[0].set_ylabel('accuracy')\n",
    "axs[0].set_xlabel('epoch')\n",
    "axs[0].legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "axs[1].plot(history.history['loss'])\n",
    "axs[1].plot(history.history['val_loss'])\n",
    "axs[1].set_title('model loss')\n",
    "axs[1].set_ylabel('loss')\n",
    "axs[1].set_xlabel('epoch')\n",
    "axs[1].legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 0,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
